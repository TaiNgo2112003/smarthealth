from flask import Flask, jsonify, request, render_template, url_for
import requests
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing import image
import json
from werkzeug.utils import secure_filename
from dotenv import load_dotenv
from flask import Flask, render_template, redirect, url_for, request, session, flash
import joblib
import pandas as pd
# Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()
# Kh·ªüi t·∫°o Flask App
app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'static/uploads'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # Gi·ªõi h·∫°n 16MB
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)




# ========== C·∫§U H√åNH API GEMINI ==========
API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyDte6xaAsNwx4cuEtnXXQGqMXJP7qtQDDI")
MODEL_NAME = "gemini-2.0-flash"  # ƒê√£ thay ƒë·ªïi sang gemini-2.0-flash cho r·∫ª v√† mi·ªÖn ph√≠
API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME}:generateContent?key={API_KEY}"

def chat_with_gemini(prompt):
    """Giao ti·∫øp v·ªõi API Gemini"""
    headers = {"Content-Type": "application/json"}
    data = {"contents": [{"parts": [{"text": prompt}]}]}

    try:
        response = requests.post(API_URL, headers=headers, json=data, timeout=30)
        response.raise_for_status()
        result = response.json()
        return result.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "Kh√¥ng c√≥ ph·∫£n h·ªìi t·ª´ Gemini.")
    except requests.exceptions.RequestException as e:
        return f"L·ªói k·∫øt n·ªëi API: {str(e)}"
    except Exception as e:
        return f"L·ªói x·ª≠ l√Ω ph·∫£n h·ªìi: {str(e)}"

# ========== FIX L·ªñI BATCH NORMALIZATION ==========
class CustomBatchNormalization(tf.keras.layers.BatchNormalization):
    """Custom BatchNorm ƒë·ªÉ fix l·ªói deserialization"""
    def __init__(self, axis=-1, **kwargs):
        if isinstance(axis, list):
            axis = axis[0] if len(axis) > 0 else -1
        super().__init__(axis=axis, **kwargs)

# ƒêƒÉng k√Ω custom layer
tf.keras.utils.get_custom_objects().update({
    'BatchNormalization': CustomBatchNormalization
})

# ========== LOAD M√î H√åNH ==========
def load_model_safely(model_path):
    """T·∫£i m√¥ h√¨nh v·ªõi nhi·ªÅu ph∆∞∆°ng ph√°p d·ª± ph√≤ng"""
    try:
        # Ph∆∞∆°ng ph√°p 1: T·∫£i th√¥ng th∆∞·ªùng
        model = tf.keras.models.load_model(model_path, compile=False)
        print("‚úÖ M√¥ h√¨nh t·∫£i th√†nh c√¥ng v·ªõi compile=False")
        print("üîç Input shape c·ªßa m√¥ h√¨nh:", model.input_shape)
        print("üîç Output shape c·ªßa m√¥ h√¨nh:", model.output_shape)
        print("üîç C√°c l·ªõp ƒë·∫ßu ti√™n c·ªßa m√¥ h√¨nh:")
        model.summary(line_length=120)
        return model
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói ph∆∞∆°ng ph√°p 1: {str(e)}")
        try:
            # Ph∆∞∆°ng ph√°p 2: D√πng custom_objects
            model = tf.keras.models.load_model(
                model_path,
                compile=False,
                custom_objects={'BatchNormalization': CustomBatchNormalization}
            )
            print("‚úÖ M√¥ h√¨nh t·∫£i th√†nh c√¥ng v·ªõi custom_objects")
            print("üîç Input shape c·ªßa m√¥ h√¨nh:", model.input_shape)
            print("üîç Output shape c·ªßa m√¥ h√¨nh:", model.output_shape)
            print("üîç C√°c l·ªõp ƒë·∫ßu ti√™n c·ªßa m√¥ h√¨nh:")
            model.summary(line_length=120)
            return model
        except Exception as e:
            print(f"‚ùå L·ªói nghi√™m tr·ªçng: {str(e)}")
            return None

# T·∫£i m√¥ h√¨nh
model = load_model_safely("trained_model.h5")

# ========== C·∫§U H√åNH M√î H√åNH ==========
IMAGE_SIZE = (350, 350)


# Load class labels
try:
    train_folder = os.path.join('dataset', 'train')
    class_labels = sorted([d for d in os.listdir(train_folder) if os.path.isdir(os.path.join(train_folder, d))])
    print(f"‚úÖ Loaded {len(class_labels)} class labels")
except Exception as e:
    print(f"‚ùå L·ªói load class labels: {str(e)}")
    class_labels = []

# √Ånh x·∫° t√™n b·ªánh
disease_mapping = {
    "adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib": "Ung th∆∞ tuy·∫øn - Th√πy d∆∞·ªõi ph·ªïi tr√°i (Giai ƒëo·∫°n Ib)",
    "large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa": "Ung th∆∞ t·∫ø b√†o l·ªõn - R·ªën ph·ªïi tr√°i (Giai ƒëo·∫°n IIIa)",
    "normal": "B√¨nh th∆∞·ªùng - Kh√¥ng c√≥ d·∫•u hi·ªáu b·ªánh",
    "squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa": "Ung th∆∞ bi·ªÉu m√¥ v·∫£y - R·ªën ph·ªïi tr√°i (Giai ƒëo·∫°n IIIa)"
}

# ========== TI·ªÄN X·ª¨ L√ù ·∫¢NH ==========
def load_and_preprocess_image(img_path):
    """Ti·ªÅn x·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o"""
    try:
        img = image.load_img(img_path, target_size=IMAGE_SIZE)
        img_array = image.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0)
        img_array = img_array / 255.0  # Chu·∫©n h√≥a [0,1]
        return img_array
    except Exception as e:
        print(f"L·ªói ti·ªÅn x·ª≠ l√Ω ·∫£nh: {str(e)}")
        return None


# ========== ROUTES ==========
@app.route('/')
def home():
    return render_template('index.html')

@app.route('/predict_page', methods=['GET', 'POST'])
def predict_page():
    # X·ª≠ l√Ω khi submit form (POST)
    if request.method == 'POST':
        if 'file' not in request.files:
            return render_template('predict.html', error="Kh√¥ng c√≥ file ƒë∆∞·ª£c t·∫£i l√™n")
        
        file = request.files['file']
        if file.filename == '':
            return render_template('predict.html', error="Kh√¥ng c√≥ file ƒë∆∞·ª£c ch·ªçn")

        try:
            # L∆∞u file
            filename = secure_filename(file.filename)
            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(filepath)
            
            # Ki·ªÉm tra m√¥ h√¨nh
            if model is None:
                return render_template('predict.html', error="M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c t·∫£i. Vui l√≤ng th·ª≠ l·∫°i sau.")
            
            # Ti·ªÅn x·ª≠ l√Ω v√† d·ª± ƒëo√°n
            img_array = load_and_preprocess_image(filepath)
            if img_array is None:
                return render_template('predict.html', error="L·ªói x·ª≠ l√Ω ·∫£nh. Vui l√≤ng th·ª≠ v·ªõi ·∫£nh kh√°c.")
            print(f"Shape of input to model: {img_array.shape}")

            predictions = model.predict(img_array)
            predicted_class = np.argmax(predictions[0])
            
            # L·∫•y k·∫øt qu·∫£
            if predicted_class < len(class_labels):
                raw_label = class_labels[predicted_class]
                predicted_label = disease_mapping.get(raw_label, raw_label)
                confidence = float(np.max(predictions[0]))
            else:
                predicted_label = "Kh√¥ng x√°c ƒë·ªãnh"
                confidence = 0.0
            
            return render_template('predict.html', 
                                prediction=predicted_label,
                                confidence=f"{confidence:.2%}",
                                image_url=url_for('static', filename=f'uploads/{filename}'),
                                error=None)
        
        except Exception as e:
            print(f"L·ªói d·ª± ƒëo√°n: {str(e)}")
            return render_template('predict.html', error=f"L·ªói h·ªá th·ªëng: {str(e)}")
    
    # X·ª≠ l√Ω khi GET request (hi·ªÉn th·ªã form)
    return render_template('predict.html', 
                         prediction=None, 
                         confidence=None, 
                         image_url=None, 
                         error=None)

@app.route("/chatbox", methods=["GET", "POST"])
def chatbox():
    if request.method == "POST":
        user_input = request.form.get("user_input", "").strip()
        if not user_input:
            return render_template("chatbox_AI.html", error="Vui l√≤ng nh·∫≠p c√¢u h·ªèi")
        
        # Gh√©p prompt ƒë·ªãnh danh AI Y t·∫ø
        prompt = f"""
        B·∫°n l√† m·ªôt tr√≠ tu·ªá nh√¢n t·∫°o chuy√™n ng√†nh Y t·∫ø. 
        H√£y tr·∫£ l·ªùi ch√≠nh x√°c, d·ªÖ hi·ªÉu v√† d·ª±a tr√™n ki·∫øn th·ª©c y h·ªçc c·∫≠p nh·∫≠t.
        C√¢u h·ªèi: {user_input}
        """

        response = chat_with_gemini(prompt)
        return render_template("chatbox_AI.html", 
                             user_input=user_input, 
                             response=response)
    
    return render_template("chatbox_AI.html", user_input="", response="")



# ========== AUTH ROUTES ==========
app.secret_key = os.urandom(24)  # Required for session

@app.route('/account')
def account():
    """Redirect to login page"""
    return redirect(url_for('login'))

@app.route('/login')
def login():
    return render_template('account/SignUp_SignIn.html')
@app.route('/admin_dashboard')
def admin_dashboard():
    return render_template('admin/admin_dashboard.html')


@app.route('/register', methods=['GET'])
def register():
    """Render register page"""
    return render_template('account/SignUp_SignIn.html')

@app.route('/logout')
def logout():
    """Handle logout"""
    session.clear()
    flash('B·∫°n ƒë√£ ƒëƒÉng xu·∫•t th√†nh c√¥ng', 'info')
    return redirect(url_for('login'))

# ========== PROTECTED ROUTES ==========
@app.route('/dashboard')
def dashboard():
    
    """Trang dashboard sau khi ƒëƒÉng nh·∫≠p"""
    # Ki·ªÉm tra session ho·∫∑c token n·∫øu c·∫ßn
    if 'user_email' not in session:
        flash('B·∫°n c·∫ßn ƒëƒÉng nh·∫≠p ƒë·ªÉ truy c·∫≠p trang n√†y!', 'warning')
        return redirect(url_for('login'))
    return render_template('dashboard.html')
# ========== MEDICAL RECORDS ==========
@app.route("/profile", methods=["GET", "POST"])
def medical_records():
    """Trang h·ªì s∆° b·ªánh √°n"""
    return render_template('profile/Medical_Records.html')
# ========== BOOK APPOINTMENT ==========
@app.route("/book_appointment", methods=["GET", "POST"])
def book_appointment():
    return render_template('appointment/book_appointment.html')
# ========== PREDICT DIASEASE BASE ON SYMPTOMS ==========
# Load model v√† c√°c th√†nh ph·∫ßn ƒë√£ l∆∞u
# Load model v√† c√°c th√†nh ph·∫ßn ƒë√£ l∆∞u
model1 = joblib.load('saved_model/best_model.pkl')
label_encoders = joblib.load('saved_model/label_encoders.pkl')
feature_names = joblib.load('saved_model/feature_names.pkl')
disease_names = joblib.load('saved_model/disease_encoder.pkl')  # T·∫£i t√™n b·ªánh

print("‚úÖ M√¥ h√¨nh v√† c√°c th√†nh ph·∫ßn ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng:", disease_names)

@app.route('/symptoms', methods=['GET', 'POST'])
def symptoms():
    if request.method == 'POST':
        # L·∫•y d·ªØ li·ªáu t·ª´ form
        input_data = {
            'Fever': request.form.get('fever'),
            'Cough': request.form.get('cough'),
            'Fatigue': request.form.get('fatigue'),
            'Difficulty Breathing': request.form.get('breathing'),
            'Age': int(request.form.get('age')),
            'Gender': request.form.get('gender'),
            'Blood Pressure': request.form.get('blood_pressure'),
            'Cholesterol Level': request.form.get('cholesterol')
        }
        
        # Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
        input_df = pd.DataFrame([input_data])
        
        # √Åp d·ª•ng encoding
        for col in ['Fever', 'Cough', 'Fatigue', 'Difficulty Breathing', 'Gender']:
            input_df[col] = label_encoders[col].transform(input_df[col])
        
        # One-Hot Encoding
        input_df = pd.get_dummies(input_df)
        
        # ƒê·∫£m b·∫£o ƒë·ªß features nh∆∞ khi train
        for col in feature_names:
            if col not in input_df.columns:
                input_df[col] = 0
        
        # D·ª± ƒëo√°n
        prediction_encoded = model1.predict(input_df[feature_names])[0]
        proba = model1.predict_proba(input_df[feature_names])[0]
        
        # Chuy·ªÉn m√£ s·ªë v·ªÅ t√™n b·ªánh
        prediction = disease_names.inverse_transform([prediction_encoded])[0]
        
        # L·∫•y top 5 b·ªánh c√≥ x√°c su·∫•t cao nh·∫•t
        top5_idx = np.argsort(proba)[-5:][::-1]
        top5_encoded = model1.classes_[top5_idx]
        top5_diseases = disease_names.inverse_transform(top5_encoded)  # Chuy·ªÉn m√£ s·ªë v·ªÅ t√™n
        top5_probs = np.round(proba[top5_idx] * 100, 2)

        # Tr·∫£ v·ªÅ k·∫øt qu·∫£ render
        return render_template('result.html', 
                               prediction=prediction,
                               top5=zip(top5_diseases, top5_probs),
                               input_data=input_data)
    
    return render_template('form.html')


# ========== KH·ªûI CH·∫†Y ==========
if __name__ == '__main__':
    # Ki·ªÉm tra m√¥ h√¨nh tr∆∞·ªõc khi ch·∫°y
    if model is not None:
        print("üü¢ ·ª®ng d·ª•ng ƒë√£ s·∫µn s√†ng")
        app.run(debug=True)
    else:
        print("üî¥ Kh√¥ng th·ªÉ kh·ªüi ch·∫°y do l·ªói t·∫£i m√¥ h√¨nh")